<!doctype html>
<html class="theme-next use-motion ">
<head>
  

<!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>






  <link rel="stylesheet" type="text/css" href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5"/>




<link rel="stylesheet" type="text/css" href="/css/main.css?v=0.4.3"/>




  <meta name="keywords" content="机器学习,分类,LR,Regression,回归," />





  <link rel="shorticon icon" type="image/x-icon" href="/favicon.ico?v=0.4.3" />



<script type="text/javascript" id="hexo.configuration">
  var CONFIG = {
    scheme: '',
    analytics: {
      google: 'UA-33400960-1'
    },
    sidebar: 'post'
  };
</script>


  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?d670c0da90ecd01b8baf1ff3c3eda42e";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>



  <title> 关于Logistics Regression // 集百折 </title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><!--[if lte IE 8]>
  <div style=' clear: both; height: 59px; padding:0 0 0 15px; position: relative;margin:0 auto;'>
    <a href="http://windows.microsoft.com/en-US/internet-explorer/products/ie/home?ocid=ie6_countdown_bannercode">
      <img src="http://7u2nvr.com1.z0.glb.clouddn.com/picouterie.jpg" border="0" height="42" width="820"
           alt="You are using an outdated browser. For a faster, safer browsing experience, upgrade for free today or use other browser ,like chrome firefox safari."
           style='margin-left:auto;margin-right:auto;display: block;'/>
    </a>
  </div>
<![endif]-->

  <div class="container one-column page-post-detail">
    <div class="headband"></div>

    <div id="header" class="header">
      <div class="header-inner">
        <h1 class="site-meta">
  <span class="logo-line-before"><i></i></span>
  <a href="/" class="brand">
      <span class="logo">
        <i class="icon-logo"></i>
      </span>
      <span class="site-title">集百折</span>
  </a>
  <span class="logo-line-after"><i></i></span>
</h1>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<div class="site-nav">
  

  
    <ul id="menu" class="menu ">
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags">
            <i class="menu-item-icon icon-tags"></i> <br />
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives">
            <i class="menu-item-icon icon-archives"></i> <br />
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about">
            <i class="menu-item-icon icon-about"></i> <br />
            关于
          </a>
        </li>
      
    </ul>
  

  
</div>


      </div>
    </div>

    <div id="main" class="main">
      <div class="main-inner">
        <div id="content" class="content">
          

  <div id="posts" class="posts-expand">
    

  <div class="post post-type-normal ">
    <div class="post-header">

      
      
        <h1 class="post-title">
          
          
            
              关于Logistics Regression
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          发表于 2015-06-28
        </span>

        

        
          
        
      </div>
    </div>

    <div class="post-body">

      
      

      
        <h2 id="1-从模型开始"><a href="#1-从模型开始" class="headerlink" title="1. 从模型开始"></a>1. 从模型开始</h2><p>Logistic Regression(常被翻译做“逻辑回归”) 一种分类模型，由于算法的简单和高效，在实际中应用非常广泛，尤其是它具有出色地将众多变量糅杂在一起并最终输出一个可以当做概率的值(大熔炉即视感)，因此颇为常用。</p>
<h3 id="1-1-先从S形函数开始-Sigmoid-Function"><a href="#1-1-先从S形函数开始-Sigmoid-Function" class="headerlink" title="1.1 先从S形函数开始(Sigmoid Function)"></a>1.1 先从S形函数开始(Sigmoid Function)</h3><p>\( f(t) = \frac{e^t}{1+e^t} = \frac{1}{1+e^{-t}} \)</p>
<p>该函数的神奇之处在于，可以将原本线性无拘无束的t值困在[0,1]范围内，并变换出一条柔美的S型曲线(Sigmoid Curve)。</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/1280px-Logistic-curve.svg.png" alt="Sigmoid Curve"></p>
<p>其实该函数还有另外一个名字——<code>Logistic Function</code>.</p>
<h3 id="1-2-Logistic-Regression-Model"><a href="#1-2-Logistic-Regression-Model" class="headerlink" title="1.2 Logistic Regression Model"></a>1.2 Logistic Regression Model</h3><p>借助Logistic Function, 这里定义Logistic回归模型。</p>
<p>$$P(Y=1|X) = \frac{exp(wx+b)}{1+exp(wx+b)} $$<br>$$P(Y=0|X) = \frac{1}{1+exp(wx+b)}$$</p>
<p>其中， \( x \in R^n \)是输入， \( Y \in \) {0,1}是输出，\( w,b \)为参数(w-权值, b-偏置)</p>
<p>从上文的sigmoid function我们就可以观察到，Logistic回归模型可以将线性函数\( (wx+b) \)转换成概率P(Y=1|X)</p>
<a id="more"></a>
<h2 id="2-举个栗子"><a href="#2-举个栗子" class="headerlink" title="2. 举个栗子"></a>2. 举个栗子</h2><p>假装我们有一个现成的广告模型</p>
<table>
<thead>
<tr>
<th>输入说明X</th>
<th>训练得到的模型参数w</th>
</tr>
</thead>
<tbody>
<tr>
<td>X0, bias(上文中的wx+b的b)</td>
<td>0.1</td>
</tr>
<tr>
<td>X1, 广告和用户搜索关键字的相关度(以概率形式表示)</td>
<td>0.8</td>
</tr>
<tr>
<td>X2, 用户性别(-1:男, 1:女)</td>
<td>0.3</td>
</tr>
<tr>
<td>X3, 用户年龄(数字)</td>
<td>0.2</td>
</tr>
</tbody>
</table>
<p>此时来了一个用户，对应的输入\( X=(x0,x1,x2,x3) = (1,0.9,1,20) \)</p>
<p>则\( wx = 1 \times 0.1 + 0.9 \times 0.8 + 1 \times 0.3+20 \times 0.2 = 5.12 \)</p>
<p>所以最终的预测用户点击率为：<br>$$ P(Y=1|X) = \frac{exp(wx)}{1+exp(wx)} = \frac{exp(5.12)}{1+exp(5.12)} = 0.994 $$</p>
<h2 id="3-参数训练"><a href="#3-参数训练" class="headerlink" title="3. 参数训练"></a>3. 参数训练</h2><p>对于给定的训练集，可以采用<code>极大似然估计法</code>估计模型参数</p>
<ul>
<li>似然函数</li>
</ul>
<p>  $$ \prod_{i=1}^{N} P(Y=1|X_i)^{y_i} \times P(Y=0|X_i)^{y_i} $$</p>
<ul>
<li>对数似然函数</li>
</ul>
<p>  $$ L(w) = \sum_{i}^{N}[y_i(w x_i) - log(1+exp(w x_i))] $$</p>
<ul>
<li>目标函数</li>
</ul>
<p>  $$ w=\arg\max_{x} L(w) = \sum_{i}^{N}[y_i(w x_i) - log(1+exp(w x_i))] $$</p>
<p>这个最优化问题可以通过梯度下降法或拟牛顿法来求解。</p>
<h2 id="4-扩展到多个分类"><a href="#4-扩展到多个分类" class="headerlink" title="4. 扩展到多个分类"></a>4. 扩展到多个分类</h2><p>如果Y不止是2类问题，而是在K个类别中取值，这时问题就变为一个多分类问题。</p>
<p>有两种方式可以出处理该类问题——</p>
<ol>
<li><p>当K个类别不是互斥的时候</p>
<p>我们对每个类别训练一个二元分类器（One-vs-all），然后对输入数据X依次使用每一个训练出来的二元分类器进行判断，大于阈值的结果就统统作为输入的分类。</p>
</li>
</ol>
<ol>
<li>如果K个类别是互斥的，即 Y=k 的时候意味着Y不能取其他的值，这种情况下，假设Y的取值集合：\( {1,2,\cdots,K} \)</li>
</ol>
<p>$$\begin{aligned}<br>P(Y=k|X) &amp;= \frac{exp(w_{k}x + b)}{1+\sum_{i}^{K-1}exp(w_{i}x+b)},  k=1,2,\cdots,K-1 \\<br>P(y=K|X) &amp;= \frac{1}{1+\sum_{i}^{K-1}exp(w_{i}x+b)}\end{aligned}$$</p>
<h2 id="5-应对非线性的分类"><a href="#5-应对非线性的分类" class="headerlink" title="5. 应对非线性的分类"></a>5. 应对非线性的分类</h2><p>Logistic回归提出时用来解决线型分类问题，其分离面是一个线型超平面wx+b，如果将这个超平面改成非线性的，是否也可以正确分类呢，如果像SVM一样加入核扩展到高维是否也可行呢？</p>
<p>以下答案来自网络加上我自己的理解整理而成。</p>
<h3 id="5-1-正统方法"><a href="#5-1-正统方法" class="headerlink" title="5.1 正统方法"></a>5.1 正统方法</h3><p>回答是可以，只要使用kernel trick（kernel trick之前在SVM中提过，具体可以<a href="/2015-04-10-svm-abs/">点击查看</a>）。</p>
<p>不过，通常使用的kernel都是隐式的，也就是找不到显式地把数据从低维映射到高维的函数，而只能计算高维空间中数据点的内积。在这种情况下，Logistic Regression模型就不能再表示成$wx+b$的形式(primal form)，而只能表示成 \( \sum_i a_i \langle x_i,x \rangle +b \) 的形式(dual form)。</p>
<p>忽略那个b的话，primal form的模型的参数只有w，只需要一个数据点那么多的存储量；而dual form的模型不仅要存储各个\(a_i\)，还要存储训练数据\(x_i\)本身，这个存储量就大了。</p>
<p>SVM也是具有上面两种形式的。不过，与Logistic Regression相比，它的dual form是稀疏的——只有支持向量的\(a_i\)才非零，才需要存储相应的\(x_i\)。所以，在非线性可分的情况下，SVM用得更多。</p>
<h3 id="5-2-野路子"><a href="#5-2-野路子" class="headerlink" title="5.2 野路子"></a>5.2 野路子</h3><p>说句题外的，很多数据没有我们想象的那么复杂。</p>
<p>我在实际中发现用逻辑斯蒂回归直接硬搞，对非线性数据进行训练，也能得到一个还能接受的结果，所以有的时候先别急着上SVM或者加kernal trick，先试试暴力训练吧：）</p>
<h2 id="6-和高斯朴素贝叶斯-GNB-的关系"><a href="#6-和高斯朴素贝叶斯-GNB-的关系" class="headerlink" title="6. 和高斯朴素贝叶斯(GNB)的关系"></a>6. 和高斯朴素贝叶斯(GNB)的关系</h2><p>Gaussian Naive Bayes(GNB)是Naive Bayes的输入X为连续变量时的情况，并且假设所有的P(x|y)独立，且符合高斯分布，这种情况下有模型如下：</p>
<p>$$P(X=x|Y=k)=P(x_1,x_2,\cdots,x_n|Y=k) = \prod_{i} P(x_i|Y=k)$$</p>
<p>有些时候，GNB还有一些别的假设，(1) 方差与Y无关; (2)方差与X无关；在这两种假设成立的基础上，有</p>
<p>$$P(X|Y=k) = \sum_{i} P(x_i|Y=k) \\<br>P(x_i|Y=k) = \frac{1}{\sigma_i \sqrt{2 \pi}} e^{\frac{-(x_i -\mu_{ik})^2}{2\sigma_i^2}}$$</p>
<p>现在，根据以上的这种情况，可以推导出LR模型，过程如下：</p>
<p>$$\begin{aligned}<br>P(Y=1|X) &amp;= \frac{P(Y=1)P(X|Y=1)}{P(Y=1)P(X|Y=1)+P(Y=0)P(X|Y=0)} \\<br>&amp;= \frac{1} {1+\frac{P(Y=0)P(X|Y=0)} {P(Y=1)P(X|Y=1)} } \\<br>&amp;= \frac{1}{1+exp(ln\frac{P(Y=0)P(X|Y=0)}{P(Y=1)P(X|Y=1)})} \\<br>&amp;= \frac{1}{1+exp(ln \frac{P(Y=0)}{P(Y=1)} + ln \frac{P(X|Y=0)}{P(X|Y=1)})}<br>\end{aligned}$$</p>
<p>根据上文中提到GNB满足的假设情况，上式中的 \((ln\frac{P(Y=0)}{P(Y=1)} + ln \frac{P(X|Y=0)}{P(X|Y=1)})\)可以展开如下：</p>
<p>$$\begin{aligned}<br>ln\frac{P(Y=0)}{P(Y=1)} + ln \frac{P(X|Y=0)}{P(X|Y=1)}<br>&amp;= ln\frac{P(Y=0)}{P(Y=1)} + \sum_{i} (ln \frac{\mu_{i0} -\mu_{i1} }{ \sigma_{i}^{2} } X_{i} + \frac{\mu_{i1}^{2} - \mu{i0}^2} {2\sigma_{i}^2} )\\<br>&amp;= (ln\frac{P(Y=0)}{P(Y=1)} + \sum{i} ln \frac{\mu_{i1}^{2} - \mu{i0}^2} {2\sigma_{i}^2})+ \sum_{i} ln \frac{\mu_{i0} -\mu_{i1} }{ \sigma_{i}^{2} } X_{i}  \\<br>&amp;= w_0 + \sum_i w_i x_i<br>\end{aligned}$$</p>
<p>因此，</p>
<p>$$P(Y=1|X) = \frac{1}{1+exp(w_0 + \sum_i w_i x_i)}$$</p>
<p>看，这就是Logistic Regression的模型呀！</p>
<p>可以看到，这个概率和Logistic回归中的形式是一样的。这种情况下GNB和LR会学习到同一个模型。据说，在更一般的假设（P(x|y)的分布属于指数分布族）下，都可以得到类似的结论，是不是有一种条条大路通罗马的感觉？</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol>
<li><p>CMU Machine Learning (10-701/15-781, Spring 2011)</p>
</li>
<li><p>李航, 《统计学习方法》</p>
</li>
<li><p>吴军, 《数学之美》</p>
</li>
</ol>

      
    </div>

    <div class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/机器学习/"> #机器学习 </a>
          
            <a href="/tags/分类/"> #分类 </a>
          
            <a href="/tags/LR/"> #LR </a>
          
            <a href="/tags/Regression/"> #Regression </a>
          
            <a href="/tags/回归/"> #回归 </a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-prev post-nav-item">
            
              <a href="/2015-07-02-Notice/">博客搬家</a>
            
          </div>

          <div class="post-nav-next post-nav-item">
            
              <a href="/2015-06-02-how-to-kill-cockroach/">[日常生活]如何有效杀灭蟑螂</a>
            
          </div>
        </div>
      

      
      
    </div>
  </div>



    <div class="post-spread">
      
        <!-- JiaThis Button BEGIN -->
<div class="jiathis_style">
  <a class="jiathis_button_tsina"></a>
  <a class="jiathis_button_tqq"></a>
  <a class="jiathis_button_weixin"></a>
  <a class="jiathis_button_cqq"></a>
  <a class="jiathis_button_douban"></a>
  <a class="jiathis_button_renren"></a>
  <a class="jiathis_button_qzone"></a>
  <a class="jiathis_button_kaixin001"></a>
  <a class="jiathis_button_copy"></a>
  <a href="http://www.jiathis.com/share" class="jiathis jiathis_txt jiathis_separator jtico jtico_jiathis" target="_blank"></a>
  <a class="jiathis_counter_style"></a>
</div>
<script type="text/javascript" >
  var jiathis_config={
    hideMore:false
  }
</script>
<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js" charset="utf-8"></script>
<!-- JiaThis Button END -->

      
    </div>

    
      <div class="comments" id="comments">
        
      </div>
    
  </div>


        </div>

        
      </div>


      
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <div id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <div class="site-overview">
        <div class="site-author motion-element">
          <img class="site-author-image" src="/images/default_avatar.jpg" alt="Marvin Wang" />
          <p class="site-author-name">Marvin Wang</p>
        </div>
        <p class="site-description motion-element"></p>
        <div class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">49</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          <div class="site-state-item site-state-categories">
            
              <span class="site-state-item-count">0</span>
              <span class="site-state-item-name">分类</span>
              
          </div>

          <div class="site-state-item site-state-tags">
            <a href="/tags">
              <span class="site-state-item-count">55</span>
              <span class="site-state-item-name">标签</span>
              </a>
          </div>

        </div>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
              <a href="https://github.com/manmadewind" target="_blank">GitHub</a>
            </span>
            
              <span class="links-of-author-item">
              <a href="http://stackoverflow.com/users/2341528/marvin-w" target="_blank">stackOverflow</a>
            </span>
            
              <span class="links-of-author-item">
              <a href="http://book.douban.com/people/1210542/collect" target="_blank">读书清单</a>
            </span>
            
          
        </div>

        
        

        <div class="links-of-author motion-element">
          
        </div>
        
      </div>

      
        <div class="post-toc-wrap sidebar-panel-active">
          <div class="post-toc-indicator-top post-toc-indicator"></div>
          <div class="post-toc">
            
            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-从模型开始"><span class="nav-number">1.</span> <span class="nav-text">1. 从模型开始</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1-先从S形函数开始-Sigmoid-Function"><span class="nav-number">1.1.</span> <span class="nav-text">1.1 先从S形函数开始(Sigmoid Function)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-Logistic-Regression-Model"><span class="nav-number">1.2.</span> <span class="nav-text">1.2 Logistic Regression Model</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-举个栗子"><span class="nav-number">2.</span> <span class="nav-text">2. 举个栗子</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-参数训练"><span class="nav-number">3.</span> <span class="nav-text">3. 参数训练</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-扩展到多个分类"><span class="nav-number">4.</span> <span class="nav-text">4. 扩展到多个分类</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-应对非线性的分类"><span class="nav-number">5.</span> <span class="nav-text">5. 应对非线性的分类</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#5-1-正统方法"><span class="nav-number">5.1.</span> <span class="nav-text">5.1 正统方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-2-野路子"><span class="nav-number">5.2.</span> <span class="nav-text">5.2 野路子</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-和高斯朴素贝叶斯-GNB-的关系"><span class="nav-number">6.</span> <span class="nav-text">6. 和高斯朴素贝叶斯(GNB)的关系</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#参考资料"><span class="nav-number">7.</span> <span class="nav-text">参考资料</span></a></li></ol></div>
            
          </div>
          <div class="post-toc-indicator-bottom post-toc-indicator"></div>
        </div>
      

    </div>
  </div>


    </div>

    <div id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">
  
  &copy; &nbsp;  2012 - 
  2017
  <span class="with-love">
    <i class="icon-heart"></i>
  </span>
  <span class="author">Marvin Wang</span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="http://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT
  </a>
</div>



      </div>
    </div>

    <div class="back-to-top"></div>
  </div>

  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  

  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js"></script>
  <script type="text/javascript" src="/js/fancy-box.js?v=0.4.3"></script>


  <script type="text/javascript" src="/js/helpers.js?v=0.4.3"></script>
  

  <script type="text/javascript" src="/vendors/velocity/velocity.min.js"></script>
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js"></script>

  <script type="text/javascript" src="/js/motion_global.js?v=0.4.3" id="motion.global"></script>



  <script type="text/javascript" src="/js/search-toggle.js"></script>

  
  
<script type="text/javascript" src="/js/bootstrap.scrollspy.js?v=0.4.3" id="bootstrap.scrollspy.custom"></script>


<script type="text/javascript" id="sidebar.toc.highlight">
  $(document).ready(function () {
    var tocSelector = '.post-toc';
    var $tocSelector = $(tocSelector);
    var activeCurrentSelector = '.active-current';

    $tocSelector
      .on('activate.bs.scrollspy', function () {
        var $currentActiveElement = $(tocSelector + ' .active').last();

        removeCurrentActiveClass();
        $currentActiveElement.addClass('active-current');

        $tocSelector[0].scrollTop = $currentActiveElement.position().top;
      })
      .on('clear.bs.scrollspy', function () {
        removeCurrentActiveClass();
      });

    function removeCurrentActiveClass () {
      $(tocSelector + ' ' + activeCurrentSelector)
        .removeClass(activeCurrentSelector.substring(1));
    }

    function processTOC () {
      getTOCMaxHeight();
      toggleTOCOverflowIndicators();
    }

    function getTOCMaxHeight () {
      var $sidebarInner = $('.sidebar-inner');
      var height = $('.sidebar').height() -
                   $tocSelector.position().top -
                   $('.post-toc-indicator-bottom').height();

      $tocSelector.css('height', height);

      return height;
    }

    function toggleTOCOverflowIndicators () {
      tocOverflowIndicator(
        '.post-toc-indicator-top',
        $tocSelector.scrollTop() > 0 ? 'show' : 'hide'
      );

      tocOverflowIndicator(
        '.post-toc-indicator-bottom',
        $tocSelector.scrollTop() >= $tocSelector.find('ol').height() - $tocSelector.height() ? 'hide' : 'show'
      )
    }

    $(document).on('sidebar.didShow', function () {
      processTOC();
    });

    $('body').scrollspy({ target: tocSelector });
    $(window).on('resize', function () {
      if ( $('.sidebar').hasClass('sidebar-active') ) {
        processTOC();
      }
    });

    onScroll($tocSelector);

    function onScroll (element) {
      element.on('mousewheel DOMMouseScroll', function (event) {
          var oe = event.originalEvent;
          var delta = oe.wheelDelta || -oe.detail;
          var self = this;

          this.scrollTop += ( delta < 0 ? 1 : -1 ) * 30;
          event.preventDefault();

          toggleTOCOverflowIndicators();
      });
    }

    function tocOverflowIndicator (indicator, action) {
      $(indicator).velocity('stop').velocity({
        opacity: action === 'show' ? 0.4 : 0
      }, { duration: 100 });
    }

  });
</script>


  <script type="text/javascript" id="sidebar.nav">
    $(document).ready(function () {
      var html = $('html');

      $('.sidebar-nav li').on('click', function () {
        var item = $(this);
        var activeTabClassName = 'sidebar-nav-active';
        var activePanelClassName = 'sidebar-panel-active';
        if (item.hasClass(activeTabClassName)) {
          return;
        }

        var currentTarget = $('.' + activePanelClassName);
        var target = $('.' + item.data('target'));

        currentTarget.velocity('transition.slideUpOut', 200, function () {
          target
            .velocity('stop')
            .velocity('transition.slideDownIn', 200)
            .addClass(activePanelClassName);
        });

        item.siblings().removeClass(activeTabClassName);
        item.addClass(activeTabClassName);
      });

      $('.post-toc a').on('click', function (e) {
        e.preventDefault();
        var offset = $(escapeSelector(this.getAttribute('href'))).offset().top;
        html.velocity('stop').velocity('scroll', {
          offset: offset  + 'px',
          mobileHA: false
        });
      });

      // Expand sidebar on post detail page by default, when post has a toc.
      var $tocContent = $('.post-toc-content');
      if (isDesktop() && CONFIG.sidebar === 'post') {
        if ($tocContent.length > 0 && $tocContent.html().trim().length > 0) {
          displaySidebar();
        }
      }
    });
  </script>




  <script type="text/javascript">
    $(document).ready(function () {
      if (CONFIG.sidebar === 'always') {
        displaySidebar();
      }
    });
  </script>

  

  
  
  

  




  
  
  <script type="text/javascript" src="/js/analytics_google-analytics.js?v=0.4.3"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.6.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->


</body>
</html>
